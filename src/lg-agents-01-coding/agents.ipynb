{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "import streamlit as st\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_community.callbacks.streamlit import (\n",
    "    StreamlitCallbackHandler,\n",
    ")\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model: AzureChatOpenAI = None\n",
    "embeddings_model: AzureOpenAIEmbeddings = None\n",
    "if \"AZURE_OPENAI_API_KEY\" in os.environ:\n",
    "    model = AzureChatOpenAI(\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "        azure_deployment=os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\"),\n",
    "        openai_api_version=os.getenv(\"AZURE_OPENAI_VERSION\"),\n",
    "        temperature=0,\n",
    "        streaming=False\n",
    "    )\n",
    "    embeddings_model = AzureOpenAIEmbeddings(    \n",
    "        azure_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\"),\n",
    "        openai_api_version = os.getenv(\"AZURE_OPENAI_VERSION\"),\n",
    "        model= os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\"),\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "    )\n",
    "else:\n",
    "    token_provider = get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\")\n",
    "    model = AzureChatOpenAI(\n",
    "        azure_ad_token_provider=token_provider,\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        azure_deployment=os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\"),\n",
    "        openai_api_version=os.getenv(\"AZURE_OPENAI_VERSION\"),\n",
    "        temperature=0,\n",
    "        openai_api_type=\"azure_ad\",\n",
    "        streaming=True\n",
    "    )\n",
    "    embeddings_model = AzureOpenAIEmbeddings(    \n",
    "        azure_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\"),\n",
    "        openai_api_version = os.getenv(\"AZURE_OPENAI_VERSION\"),\n",
    "        model= os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\"),\n",
    "        azure_ad_token_provider = token_provider\n",
    "    )\n",
    "\n",
    "def llm(x):\n",
    "    return model.invoke(x).content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Dict, TypedDict, Optional\n",
    "from langgraph.graph import StateGraph, END\n",
    "import random\n",
    "import time\n",
    "\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    feedback: Optional[str] = None\n",
    "    history: Optional[str] = None\n",
    "    code: Optional[str] = None\n",
    "    specialization: Optional[str]=None\n",
    "    rating: Optional[str] = None\n",
    "    iterations: Optional[int]=None\n",
    "    code_compare: Optional[str]=None\n",
    "    actual_code: Optional[str]=None\n",
    "\n",
    "workflow = StateGraph(GraphState)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer_start= \"You are Code reviewer specialized in {}.\\\n",
    "You need to review the given code following PEP8 guidelines and potential bugs\\\n",
    "and point out issues as bullet list.\\\n",
    "Code:\\n {}\"\n",
    "\n",
    "coder_start = \"You are a Coder specialized in {}.\\\n",
    "Improve the given code given the following guidelines. Guideline:\\n {} \\n \\\n",
    "Code:\\n {} \\n \\\n",
    "Output just the improved code and nothing else.\"\n",
    "\n",
    "rating_start = \"Rate the skills of the coder on a scale of 10 given the Code review cycle with a short reason.\\\n",
    "Code review:\\n {} \\n \"\n",
    "\n",
    "code_comparison = \"Compare the two code snippets and rate on a scale of 10 to both. Dont output the codes. Revised Code: \\n {} \\n Actual Code: \\n {}\"\n",
    "\n",
    "classify_feedback = \"Are all feedback mentioned resolved in the code? Output just Yes or No.\\\n",
    "Code: \\n {} \\n Feedback: \\n {} \\n\"\n",
    "\n",
    "def handle_reviewer(state):\n",
    "    print(state)\n",
    "    history = state.get('history', '').strip()\n",
    "    code = state.get('code', '').strip()\n",
    "    specialization = state.get('specialization','').strip()\n",
    "    iterations = state.get('iterations')\n",
    "    \n",
    "    print(\"Reviewer working...\")\n",
    "    \n",
    "    feedback = llm(reviewer_start.format(specialization,code))\n",
    "    \n",
    "    return {'history':history+\"\\n REVIEWER:\\n\"+feedback,'feedback':feedback,'iterations':iterations+1}\n",
    "\n",
    "def handle_coder(state):\n",
    "    print(state)\n",
    "    history = state.get('history', '').strip()\n",
    "    feedback = state.get('feedback', '').strip()\n",
    "    code =  state.get('code','').strip()\n",
    "    specialization = state.get('specialization','').strip()\n",
    "    \n",
    "    print(\"CODER rewriting...\")\n",
    "    \n",
    "    code = llm(coder_start.format(specialization,feedback,code))\n",
    "    return {'history':history+'\\n CODER:\\n'+code,'code':code}\n",
    "\n",
    "def handle_result(state):\n",
    "    print(state)\n",
    "    print(\"Review done...\")\n",
    "    \n",
    "    history = state.get('history', '').strip()\n",
    "    code1 = state.get('code', '').strip()\n",
    "    code2 = state.get('actual_code', '').strip()\n",
    "    rating  = llm(rating_start.format(history))\n",
    "    \n",
    "    code_compare = llm(code_comparison.format(code1,code2))\n",
    "    return {'rating':rating,'code_compare':code_compare}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_node(\"handle_reviewer\",handle_reviewer)\n",
    "workflow.add_node(\"handle_coder\",handle_coder)\n",
    "workflow.add_node(\"handle_result\",handle_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deployment_ready(state):\n",
    "    deployment_ready = 1 if 'yes' in llm(classify_feedback.format(state.get('code'),state.get('feedback'))) else 0\n",
    "    total_iterations = 1 if state.get('iterations')>5 else 0\n",
    "    return \"handle_result\" if  deployment_ready or total_iterations else \"handle_coder\" \n",
    "\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"handle_reviewer\",\n",
    "    deployment_ready,\n",
    "    {\n",
    "        \"handle_result\": \"handle_result\",\n",
    "        \"handle_coder\": \"handle_coder\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.set_entry_point(\"handle_reviewer\")\n",
    "workflow.add_edge('handle_coder', \"handle_reviewer\")\n",
    "workflow.add_edge('handle_result', END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialization = 'python'\n",
    "problem = 'Generate code to train a Regression ML model using a tabular dataset following required preprocessing steps.'\n",
    "code = llm(problem)\n",
    "\n",
    "app = workflow.compile()\n",
    "conversation = app.invoke({\"history\":code,\"code\":code,'actual_code':code,\"specialization\":specialization,'iterations':0},{\"recursion_limit\":20})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
